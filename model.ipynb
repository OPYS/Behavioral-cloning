{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, ELU\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "import pickle\n",
    "from scipy import misc\n",
    "from scipy.misc import imresize\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 3)\n",
      "(39209,)\n"
     ]
    }
   ],
   "source": [
    "training_file = \"train.p\"\n",
    "testing_file = \"test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    #print(train)\n",
    "\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    #print (test)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 66, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.resize(X_train,(39209,66,200,3))\n",
    "input_shape = X_train.shape\n",
    "print (input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x:x/127.5 -1., input_shape = (66,200,3)))\n",
    "model.add(Convolution2D(24, 5, 5,border_mode='same',subsample=(2,2), dim_ordering='tf', input_shape=(66,200,3)))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(36, 5, 5, border_mode='same',subsample=(2,2)))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(48, 5, 5,subsample=(2,2)))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3,subsample=(2,2)))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3,subsample=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(ELU())\n",
    "model.add(Dense(1164))\n",
    "model.add(ELU())\n",
    "model.add(Dense(100))\n",
    "model.add(ELU())\n",
    "model.add(Dense(50))\n",
    "model.add(ELU())\n",
    "model.add(Dense(10))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1,name='output'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [-0.5, 0.5]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    #costants\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    xmin = np.min(image_data)\n",
    "    xmax = np.max(image_data) \n",
    "    \n",
    "    x = image_data    \n",
    "    x_prime = a + ((x-xmin)*(b-a))/(xmax-xmin)\n",
    "    \n",
    "    return x_prime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27446 samples, validate on 11763 samples\n",
      "Epoch 1/5\n",
      "27446/27446 [==============================] - 296s - loss: 41.7685 - acc: 0.0525 - val_loss: 597.8218 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "27446/27446 [==============================] - 286s - loss: 30.6335 - acc: 0.0535 - val_loss: 546.3282 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "27446/27446 [==============================] - 287s - loss: 30.6970 - acc: 0.0540 - val_loss: 577.4276 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "27446/27446 [==============================] - 290s - loss: 30.6386 - acc: 0.0513 - val_loss: 556.9162 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "27446/27446 [==============================] - 290s - loss: 30.6207 - acc: 0.0532 - val_loss: 586.3330 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, validation_split=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053231800627\n"
     ]
    }
   ],
   "source": [
    "print(history.history['acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "with open('model.json','w') as f:\n",
    "    json.dump(json_string,f,ensure_ascii=False)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
